"""Configuration module for Agentic RAG system"""

import os
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

from langchain_groq import ChatGroq


# Load environment variables
load_dotenv()



class Config:
    """Configuration class for RAG system"""
    
    # API Keys
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    
    # Model Configuration
    LLM_MODEL = "llama-3.1-8b-instant"
    
    # Document Processing
    CHUNK_SIZE = 500
    CHUNK_OVERLAP = 50
    
    # # Default URLs
    # DEFAULT_URLS = [
    #     "https://www.medlink.com/news/the-enduring-legacy-of-grand-rounds",

    # ]

     # Default URLs
    DEFAULT_URLS = ["https://www.google.com", ]
       



    # @classmethod
    # def get_llm(cls):
    #     """Initialize and return the LLM model"""
    #     os.environ["GROQ_API_KEY"] = cls.GROQ_API_KEY
    #     return init_chat_model(cls.LLM_MODEL)
    @classmethod
    def get_llm(cls):
        try:
            
            # groq_api_key = os.getenv("GROQ_API_KEY")
            # LLM_MODEL="llama-3.1-8b-instant"

            llm=ChatGroq(api_key=cls.GROQ_API_KEY,model=cls.LLM_MODEL)

        except Exception as e:
            raise ValueError(f"Error Ocuured With Exception : {e}")
        return llm